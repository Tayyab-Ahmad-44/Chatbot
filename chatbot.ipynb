{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.document_loaders import FireCrawlLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCMtgjCDQl7iBJsLa2iGTH0KBmsIw3UGFo\"\n",
    "DB_DIR = \"faiss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.read().split('\\n')\n",
    "\n",
    "    # Combine every two lines into one document\n",
    "    docs = []\n",
    "    for i in range(0, len(lines), 2):\n",
    "        combined_content = '\\n'.join(line.strip() for line in lines[i:i + 2] if line.strip())\n",
    "        if combined_content:\n",
    "            docs.append(Document(page_content=combined_content))\n",
    "\n",
    "    # Initialize embeddings\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "    # Create a FAISS vector database from the documents\n",
    "    vectordb = FAISS.from_documents(documents=docs, embedding=embeddings)\n",
    "    vectordb.save_local(DB_DIR)\n",
    "\n",
    "    return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db = process_file(r\"T:\\Programmingg\\Maktek\\Chatbot\\data2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"You are a knowledgeable assistant tasked with providing detailed information and guidance about the Construction Industry Scheme (CIS) as it was implemented post-April 2007. The data you will be working with is structured into different sections and content areas, each dealing with specific aspects of the scheme, such as contractor registration, subcontractor verification, deductions, compliance, and relevant legislation.\n",
    "\n",
    "When responding to user queries, you should use the following guidelines:\n",
    "\n",
    "1- Content Structure: The information is organized into numbered sections, each covering a different topic within the CIS. Begin by identifying the relevant section or content area based on the user's query.\n",
    "\n",
    "2- Contextual Understanding: Use the provided content to deliver accurate, concise, and contextually appropriate answers. If a user asks about a specific part of the scheme (e.g., subcontractor verification or monthly returns), focus on the relevant section and summarize key points.\n",
    "\n",
    "3- User Guidance: If the user's question relates to where to find certain information within the CIS documentation, guide them to the appropriate section (e.g., 'For details on subcontractor registration, refer to CISR40000').\n",
    "\n",
    "4- Handling Feedback: If the user is unsatisfied with the response or provides feedback, acknowledge their input and attempt to refine your answer by pulling from different relevant sections.\n",
    "\n",
    "5- Cautions: Do not attempt to provide legal advice or make assumptions beyond the information provided. If the answer is not within your scope, inform the user that the query is outside your remit.\n",
    "\n",
    "6- Clarity and Precision: Keep your responses clear and precise. If a term or concept is complex, provide a brief explanation or definition to aid understanding.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(vectordb, query, chat_history):\n",
    "    # Create a retriever from the FAISS vector database\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "    # Use a Llama3-70b model\n",
    "    llm = ChatGroq(\n",
    "        api_key=\"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\",\n",
    "        temperature=0,\n",
    "        model=\"llama-3.1-70b-versatile\",\n",
    "    )\n",
    "\n",
    "    # Create a ConversationalRetrievalChain with a StuffedDocumentChain\n",
    "    chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        chain_type=\"stuff\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # Format chat history to a list of tuples\n",
    "    formatted_chat_history = [(item['question'], item['answer']) for item in chat_history]\n",
    "\n",
    "    # Run the prompt and return the response\n",
    "    response = chain({\"question\": query, \"chat_history\": formatted_chat_history})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
